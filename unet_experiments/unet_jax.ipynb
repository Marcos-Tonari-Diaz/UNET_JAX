{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import flax.linen as nn\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dims [N: number of batches, H, W, C]\n",
    "class UnetJAX(nn.Module):\n",
    "    input_image_size: int\n",
    "\n",
    "    @staticmethod\n",
    "    def contracting_block(input, num_features):\n",
    "        input = nn.Conv(features=num_features, kernel_size=(3,3)) (input)\n",
    "        # input = nn.Conv(features=num_features, kernel_size=(3,3), padding='VALID') (input)\n",
    "        input = nn.relu(input)\n",
    "        input = nn.Conv(features=num_features, kernel_size=(3,3)) (input)\n",
    "        # input = nn.Conv(features=num_features, kernel_size=(3,3), padding='VALID') (input)\n",
    "        input = nn.relu(input)\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def expanding_block(input, residual_feature_map, num_features):\n",
    "        input = nn.ConvTranspose(features=num_features, kernel_size=(2,2), strides=(2,2)) (input)\n",
    "        cropped_feature_map =  residual_feature_map\n",
    "        # cropped_feature_map =  UNET_JAX.center_crop_array(residual_feature_map, input.shape[1])\n",
    "        input = jnp.concatenate((input, cropped_feature_map), axis=2)\n",
    "        input = nn.Conv(features=num_features, kernel_size=(3,3)) (input)\n",
    "        # input = nn.Conv(features=num_features, kernel_size=(3,3), padding='VALID') (input)\n",
    "        input = nn.relu(input)\n",
    "        input = nn.Conv(features=num_features, kernel_size=(3,3)) (input)\n",
    "        # input = nn.Conv(features=num_features, kernel_size=(3,3), padding='VALID') (input)\n",
    "        input = nn.relu(input)\n",
    "        return input\n",
    "\n",
    "    @staticmethod    \n",
    "    def final_block(input):\n",
    "        return nn.Conv(features=1, kernel_size=(1,1)) (input)\n",
    "        # input = nn.Conv(features=1, kernel_size=(1,1)) (input) \n",
    "        # return nn.sigmoid(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def max_pool_block(input):\n",
    "        return nn.max_pool(input, window_shape=(2,2), strides=(2,2))\n",
    "\n",
    "    @staticmethod \n",
    "    def center_crop_array(array, new_size):\n",
    "        crop_offset = (array.shape[0] - new_size)//2\n",
    "        return array[crop_offset:-crop_offset, crop_offset:-crop_offset, :]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, input):\n",
    "        contracting_out1 = self.contracting_block(input, 64)\n",
    "        max_pool_out = self.max_pool_block(contracting_out1)\n",
    "        contracting_out2 = self.contracting_block(max_pool_out, 128)\n",
    "        max_pool_out = self.max_pool_block(contracting_out2)\n",
    "        contracting_out3 = self.contracting_block(max_pool_out, 256)\n",
    "        max_pool_out = self.max_pool_block(contracting_out3)\n",
    "        contracting_out4 = self.contracting_block(max_pool_out, 512)\n",
    "        max_pool_out = self.max_pool_block(contracting_out4)\n",
    "        contracting_out5 = self.contracting_block(max_pool_out, 1024)\n",
    "        output = self.expanding_block(contracting_out5, contracting_out4, 512)\n",
    "        output = self.expanding_block(output, contracting_out3, 256)\n",
    "        output = self.expanding_block(output, contracting_out2, 128)\n",
    "        output = self.expanding_block(output, contracting_out1, 64)\n",
    "        output = self.final_block(output)\n",
    "        return output\n",
    "\n",
    "    def init_params(self, rng):\n",
    "        input_size_dummy = jnp.ones([self.input_image_size, self.input_image_size,1])\n",
    "        params = self.init(rng, input_size_dummy)\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "#changed input_image_size to 512 due to dataset shape\n",
    "unet = UnetJAX(input_image_size=512)\n",
    "unet_params = unet.init_params(key)\n",
    "#jax.tree_map(lambda x: x.shape, unet_params) # Checking output shapes\n",
    "dummy_in = jnp.ones([512,512,1])\n",
    "dummy_out = unet.apply(unet_params, dummy_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_params[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "masks = glob.glob(\"../data/isbi2015/train/label/*.png\")\n",
    "orgs = glob.glob(\"../data/isbi2015/train/image/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "imgs_list = []\n",
    "masks_list = []\n",
    "for image, mask in zip(orgs, masks):\n",
    "    imgs_list.append(jnp.array(Image.open(image).resize((512,512))))\n",
    "    masks_list.append(jnp.array(Image.open(mask).resize((512,512))))\n",
    "imgs_np = jnp.asarray(imgs_list)\n",
    "masks_np = jnp.asarray(masks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgs_np.shape, masks_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgs_np.max(), masks_np.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = jnp.asarray(imgs_np, dtype=jnp.float32)/255\n",
    "masks = jnp.asarray(masks_np, dtype=jnp.float32)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.max(), masks.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(images.shape + (1,))\n",
    "masks = masks.reshape(masks.shape + (1,))\n",
    "print(images.shape)\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_factor = 0.8\n",
    "images_train, images_test =  jnp.split(images, [int(images.shape[0]*split_factor)])\n",
    "masks_train, masks_test =  jnp.split(masks, [int(masks.shape[0]*split_factor)])\n",
    "dataset = { \"train\" :{}, \"test\": {}}\n",
    "dataset[\"train\"] = {\"images\": images_train, \"labels\": masks_train}\n",
    "dataset[\"test\"] = {\"images\": images_test, \"labels\": masks_test}\n",
    "dataset[\"train\"][\"images\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expects unnormalized log probabilities as logits\n",
    "def loss_function(logits, labels):\n",
    "    return optax.sigmoid_binary_cross_entropy(logits, labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_binary(logits):\n",
    "    logits = nn.sigmoid(logits)\n",
    "    logits = logits.round()\n",
    "    return logits\n",
    "\n",
    "def compute_accuracy(logits, labels):\n",
    "    return jnp.mean(logits_to_binary(logits) == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits, labels):\n",
    "    loss = loss_function(logits, labels)\n",
    "    accuracy = compute_accuracy(logits, labels)\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state\n",
    "\n",
    "class UnetTrainState():\n",
    "    train_state : train_state.TrainState\n",
    "    unet : UnetJAX\n",
    "    current_epoch : int = 0\n",
    "    rng : jax.random.PRNGKey\n",
    "    unet_params = None \n",
    "\n",
    "    def __init__(self, unet: UnetJAX, optimizer, seed):\n",
    "        self.unet = unet\n",
    "        self.rng = jax.random.PRNGKey(seed)\n",
    "        self.create_training_state(optimizer)\n",
    "\n",
    "    def create_training_state(self, optimizer):\n",
    "        self.unet_params = unet.init_params(self.rng)\n",
    "        self.train_state = train_state.TrainState.create(apply_fn=unet.apply, params=self.unet_params, tx=optimizer)\n",
    "\n",
    "    def print_train_metrics(self, metrics):\n",
    "        print('train epoch: %d, loss: %.4f, accuracy: %.4f' % (self.current_epoch, metrics[\"loss\"], metrics[\"accuracy\"]))\n",
    "\n",
    "    def print_eval_metrics(self, metrics):\n",
    "        print('model eval: %d, loss: %.4f, accuracy: %.4f' % (self.current_epoch, metrics[\"loss\"], metrics[\"accuracy\"]))\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        def compute_loss_function(params):\n",
    "            logits = unet.apply(self.unet_params, batch['image']) \n",
    "            loss = loss_function(logits, batch['label'])\n",
    "            return loss, logits\n",
    "        compute_loss_grads = jax.value_and_grad(compute_loss_function, has_aux=True)\n",
    "        (loss, logits), grads = compute_loss_grads(self.train_state.params)\n",
    "        self.train_state = self.train_state.apply_gradients(grads=grads)\n",
    "\n",
    "    def eval_step(self, batch):\n",
    "        logits = unet.apply(self.train_state.params, batch['image']) \n",
    "        return compute_metrics(logits, batch['label'])\n",
    "\n",
    "    # batch size is 1 image (paper)\n",
    "    def train_epoch(self, train_dataset):\n",
    "        self.rng, new_rng = jax.random.split(self.rng)\n",
    "        shuffled_indexes = jax.random.permutation(new_rng, len(train_dataset[\"images\"]))\n",
    "        for image_index in shuffled_indexes:\n",
    "            batch = {\"image\": train_dataset[\"images\"][image_index], \"label\": train_dataset[\"labels\"][image_index]}\n",
    "            self.train_step(batch)\n",
    "            batch_metrics = self.eval_step(batch)\n",
    "            batch_metrics = jax.device_get(batch_metrics)\n",
    "            self.print_train_metrics(batch_metrics)\n",
    "            self.current_epoch+=1\n",
    "    \n",
    "    def eval_model(self, test_dataset):\n",
    "        batch = {\"image\": test_dataset[\"images\"], \"label\": test_dataset[\"labels\"]}\n",
    "        metrics = self.eval_step(batch)\n",
    "        metrics = jax.device_get(metrics)\n",
    "        self.print_eval_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UnetJAX(input_image_size=512)\n",
    "optimizer = optax.sgd(learning_rate=0.1, momentum=0.99)\n",
    "unet_train_state = UnetTrainState(unet, optimizer, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_train_state.train_epoch(train_dataset=dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_train_state.eval_model(test_dataset=dataset[\"test\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6492e545f0af335fe28b1dcaae8a2553f2b3b5844f2707f3bf67d1d5651f0cb9"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('jax': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
